
module dram_dp(
      dp_data_mecc0, dp_data_mecc1, dp_data_mecc2, dp_data_mecc3, 
   dp_data_mecc4, dp_data_mecc5, dp_data_mecc6, dp_data_mecc7, 
   dram_io_data_out, dp_data_in, dp_ecc_in, dp_data_valid, 
      clk, rst_l, l2if_data_mecc0, l2if_data_mecc1, l2if_data_mecc2, 
   l2if_data_mecc3, l2if_data_mecc4, l2if_data_mecc5, 
   l2if_data_mecc6, l2if_data_mecc7, io_dram_data_in, io_dram_ecc_in, 
   io_dram_data_valid, que_bypass_scrb_data, que_mem_addr, que_mem_data, 
   dram_fail_over_mask, l2if_scrb_data_en, l2if_scrb_data, 
   l2if_scrb_ecc, err_inj_reg, err_mask_reg, que_wr_channel_mux, 
   ch1_que_mem_data, ch1_dp_data_mecc0, ch1_dp_data_mecc1, 
   ch1_dp_data_mecc2, ch1_dp_data_mecc3, ch1_dp_data_mecc4, 
   ch1_dp_data_mecc5, ch1_dp_data_mecc6, ch1_dp_data_mecc7,
   que_st_cmd_addr_parity, que_channel_disabled, sshot_err_reg
   );


input		clk;
input		rst_l;

input [3:0]	l2if_data_mecc0;
input [3:0]	l2if_data_mecc1;
input [3:0]	l2if_data_mecc2;
input [3:0]	l2if_data_mecc3;
input [3:0]	l2if_data_mecc4;
input [3:0]	l2if_data_mecc5;
input [3:0]	l2if_data_mecc6;
input [3:0]	l2if_data_mecc7;

input [255:0]   io_dram_data_in;		input [31:0]    io_dram_ecc_in;			input		io_dram_data_valid;		
input		que_bypass_scrb_data;
input [4:0]	que_mem_addr;
input [255:0]   que_mem_data;
input		que_st_cmd_addr_parity;
input		que_channel_disabled;

input [34:0]	dram_fail_over_mask;

input		l2if_scrb_data_en;
input [255:0] 	l2if_scrb_data;
input [33:0] 	l2if_scrb_ecc;

input		err_inj_reg;
input [15:0]    err_mask_reg;

input		que_wr_channel_mux;
input [255:0]   ch1_que_mem_data;

input [3:0]	ch1_dp_data_mecc0;
input [3:0]	ch1_dp_data_mecc1;
input [3:0]	ch1_dp_data_mecc2;
input [3:0]	ch1_dp_data_mecc3;
input [3:0]	ch1_dp_data_mecc4;
input [3:0]	ch1_dp_data_mecc5;
input [3:0]	ch1_dp_data_mecc6;
input [3:0]	ch1_dp_data_mecc7;

output [3:0]	dp_data_mecc0;
output [3:0]	dp_data_mecc1;
output [3:0]	dp_data_mecc2;
output [3:0]	dp_data_mecc3;
output [3:0]	dp_data_mecc4;
output [3:0]	dp_data_mecc5;
output [3:0]	dp_data_mecc6;
output [3:0]	dp_data_mecc7;


output [287:0]  dram_io_data_out;

output [255:0] 	dp_data_in;
output [31:0] 	dp_ecc_in;
output		dp_data_valid;


input sshot_err_reg;


wire [15:0]	;
wire [15:0]	eccl;
wire [15:0]	dp_mux_ecc_hi;
wire [15:0]	dp_mux_ecc_pre_xor_hi;
wire [15:0]	dp_mux_ecc_lo;
wire [15:0]	dp_mux_ecc_pre_xor_lo;
wire [287:0]	dp_pad_data;
wire [287:0]	dp_wr_data_muxed_nibbles;
wire [255:0]	dp_mux_data;
wire [33:0]	dp_scrb_ecc0;
wire [33:0]	dp_scrb_ecc1;
wire 		dp_scrb_data_en_cnt_in;
wire 		dp_scrb_data_en_cnt;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [15:0]	;
wire [15:0]	dp_mux_ecc_hi;
wire [15:0]	dp_mux_ecc_pre_xor_hi;
wire [15:0]	dp_mux_ecc_lo;
wire [15:0]	dp_mux_ecc_pre_xor_lo;
wire [287:0]	dp_pad_data;
wire [287:0]	dp_wr_data_muxed_nibbles;
wire [255:0]	dp_mux_data;
wire [33:0]	dp_scrb_ecc0;
wire [33:0]	dp_scrb_ecc1;
wire 		dp_scrb_data_en_cnt_in;
wire 		dp_scrb_data_en_cnt;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [15:0]	;
wire [15:0]	dp_mux_ecc_pre_xor_hi;
wire [15:0]	dp_mux_ecc_lo;
wire [15:0]	dp_mux_ecc_pre_xor_lo;
wire [287:0]	dp_pad_data;
wire [287:0]	dp_wr_data_muxed_nibbles;
wire [255:0]	dp_mux_data;
wire [33:0]	dp_scrb_ecc0;
wire [33:0]	dp_scrb_ecc1;
wire 		dp_scrb_data_en_cnt_in;
wire 		dp_scrb_data_en_cnt;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [15:0]	;
wire [15:0]	dp_mux_ecc_lo;
wire [15:0]	dp_mux_ecc_pre_xor_lo;
wire [287:0]	dp_pad_data;
wire [287:0]	dp_wr_data_muxed_nibbles;
wire [255:0]	dp_mux_data;
wire [33:0]	dp_scrb_ecc0;
wire [33:0]	dp_scrb_ecc1;
wire 		dp_scrb_data_en_cnt_in;
wire 		dp_scrb_data_en_cnt;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [15:0]	;
wire [15:0]	dp_mux_ecc_pre_xor_lo;
wire [287:0]	dp_pad_data;
wire [287:0]	dp_wr_data_muxed_nibbles;
wire [255:0]	dp_mux_data;
wire [33:0]	dp_scrb_ecc0;
wire [33:0]	dp_scrb_ecc1;
wire 		dp_scrb_data_en_cnt_in;
wire 		dp_scrb_data_en_cnt;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [15:0]	;
wire [287:0]	dp_pad_data;
wire [287:0]	dp_wr_data_muxed_nibbles;
wire [255:0]	dp_mux_data;
wire [33:0]	dp_scrb_ecc0;
wire [33:0]	dp_scrb_ecc1;
wire 		dp_scrb_data_en_cnt_in;
wire 		dp_scrb_data_en_cnt;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [287:0]	;
wire [287:0]	dp_wr_data_muxed_nibbles;
wire [255:0]	dp_mux_data;
wire [33:0]	dp_scrb_ecc0;
wire [33:0]	dp_scrb_ecc1;
wire 		dp_scrb_data_en_cnt_in;
wire 		dp_scrb_data_en_cnt;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [287:0]	;
wire [255:0]	dp_mux_data;
wire [33:0]	dp_scrb_ecc0;
wire [33:0]	dp_scrb_ecc1;
wire 		dp_scrb_data_en_cnt_in;
wire 		dp_scrb_data_en_cnt;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [255:0]	;
wire [33:0]	dp_scrb_ecc0;
wire [33:0]	dp_scrb_ecc1;
wire 		dp_scrb_data_en_cnt_in;
wire 		dp_scrb_data_en_cnt;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [33:0]	;
wire [33:0]	dp_scrb_ecc1;
wire 		dp_scrb_data_en_cnt_in;
wire 		dp_scrb_data_en_cnt;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [33:0]	;
wire 		dp_scrb_data_en_cnt_in;
wire 		dp_scrb_data_en_cnt;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire 		;
wire 		dp_scrb_data_en_cnt;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire 		;
wire		dp_scrb_wr_en;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire		;
wire		dp_scrb_data0_en;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire		;
wire		dp_scrb_data1_en;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire		;
wire		dp_scrb_data_en;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire		;
wire [255:0]	dp_scrb_cor_data;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [255:0]	;
wire [255:0]	dp_scrb_data0;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [255:0]	;
wire [255:0]	dp_scrb_data1;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [255:0]	;
wire [33:0]	dp_scrb_cor_ecc;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [33:0]	;
wire [3:0]	dp_data_mecc0_int;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [3:0]	;
wire [3:0]	dp_data_mecc1_int;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [3:0]	;
wire [3:0]	dp_data_mecc2_int;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [3:0]	;
wire [3:0]	dp_data_mecc3_int;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [3:0]	;
wire [3:0]	dp_data_mecc4_int;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [3:0]	;
wire [3:0]	dp_data_mecc5_int;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [3:0]	;
wire [3:0]	dp_data_mecc6_int;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [3:0]	;
wire [3:0]	dp_data_mecc7_int;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [3:0]	;
wire 		dp_scrb_wr_data_en_cnt_in;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire 		;
wire 		dp_scrb_wr_data_en_cnt;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire 		;

//////////////////////////////////////////////////////////////////
// CODE
//////////////////////////////////////////////////////////////////

////////////////////////////////////////////////
// Scrub and Initial data
////////////////////////////////////////////////

// Flop the scrb enable and data from cpu clk to dramclk
dffrl_ns #(1)   ff_data_en(
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;



dffrl_ns #(1)   (
                .din(l2if_scrb_data_en),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan(
                .din(),
                .q(dp_scrb_data_en),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
                .q(),
		.rst_l(rst_l),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
		.rst_l(),
                .clk(clk));

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
                .clk());

dff_ns #(256)   ff_l2_scrb_data(
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan));

dff_ns #(256)   (
                .din(l2if_scrb_data[255:0]),
                .q(dp_scrb_cor_data[255:0]),
                .clk(clk));

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan(
                .din([255:0]),
                .q([255:0]),
                .clk());

dff_ns #(34)    ff_l2_scrb_ecc(
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan));

dff_ns #(34)    (
                .din(l2if_scrb_ecc[33:0]),
                .q(dp_scrb_cor_ecc[33:0]),
                .clk(clk));

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan(
                .din([33:0]),
                .q([33:0]),
                .clk());

// counter to keep track of data enable for capturing scrb data

assign dp_scrb_wr_en = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan));


assign  = dp_scrb_data_en | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan =  | (|(dp_scrb_data_en_cnt));
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan | (|());
assign dp_scrb_data_en_cnt_in = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan));
assign  = dp_scrb_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan =  + 1'b1;

dffrle_ns #(1)  ff_wr_en(
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan + 1bb;

dffrle_ns #(1)  (
                .din(dp_scrb_data_en_cnt_in),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan(
                .din(),
                .q(dp_scrb_data_en_cnt),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
                .q(),
		.rst_l(rst_l),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
		.rst_l(),
		.en(dp_scrb_wr_en),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
		.en(),
                .clk(clk));

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
                .clk());

assign dp_scrb_data0_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan));

assign  = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan =  & (dp_scrb_data_en_cnt == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan & ( == 1'h0);
assign dp_scrb_data1_en = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan == 1hh);
assign  = dp_scrb_data_en & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan =  & (dp_scrb_data_en_cnt == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan & ( == 1'h1);

// scrub and initial data holders waiting to be written to dram

dffrle_ns #(256) ff_scrb_wr_data0(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan == 1hh);


dffrle_ns #(256) (
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data0[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan(
                .din({[63:0],[127:64], [191:128], 
				[255:192]}),
                .q([255:0]),
		.rst_l(),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
		.en(),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
                .clk());

dffrle_ns #(34) ff_scrb_wr_ecc0(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan));

dffrle_ns #(34) (
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc0[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan(
                .din([33:0]),
                .q([33:0]),
		.rst_l(),
		.en(dp_scrb_data0_en),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
		.en(),
                .clk(clk));

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
                .clk());

dffrle_ns #(256)    ff_scrb_wr_data1(
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan));

dffrle_ns #(256)    (
                .din({dp_scrb_cor_data[63:0],dp_scrb_cor_data[127:64], dp_scrb_cor_data[191:128], 
				dp_scrb_cor_data[255:192]}),
                .q(dp_scrb_data1[255:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan(
                .din({[63:0],[127:64], [191:128], 
				[255:192]}),
                .q([255:0]),
		.rst_l(),
		.en(dp_scrb_data1_en),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
		.en(),
                .clk(clk));

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
                .clk());

dffrle_ns #(34) ff_scrb_wr_ecc1(
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan));

dffrle_ns #(34) (
                .din(dp_scrb_cor_ecc[33:0]),
                .q(dp_scrb_ecc1[33:0]),
		.rst_l(rst_l),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan(
                .din([33:0]),
                .q([33:0]),
		.rst_l(),
		.en(dp_scrb_data1_en),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
		.en(),
                .clk(clk));

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
                .clk());

/////////////////////////////////////////
// Check if l2 data needs to be piosoned
/////////////////////////////////////////

wire [3:0]	dp_pioson_l2_data;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan));


wire [3:0]	;
wire [1:0]	dp_pioson_l2_chunk;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [1:0]	;
wire [3:0]	que_mem_addr_d1;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire [3:0]	;
wire		que_dp_wr_data_vld;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
wire		;

dffrl_ns #(32) ff_data_mecc(
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;

dffrl_ns #(32) (
	.din({l2if_data_mecc0[3:0],l2if_data_mecc1[3:0],l2if_data_mecc2[3:0],l2if_data_mecc3[3:0],
	    l2if_data_mecc4[3:0],l2if_data_mecc5[3:0],l2if_data_mecc6[3:0],l2if_data_mecc7[3:0]}),
        .q({dp_data_mecc0[3:0],dp_data_mecc1[3:0],dp_data_mecc2[3:0],dp_data_mecc3[3:0],
		dp_data_mecc4[3:0],dp_data_mecc5[3:0],dp_data_mecc6[3:0],dp_data_mecc7[3:0]}),
	.rst_l(rst_l),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan(
	.din({[3:0],[3:0],[3:0],[3:0],
	    [3:0],[3:0],[3:0],[3:0]}),
        .q({[3:0],[3:0],[3:0],[3:0],
		[3:0],[3:0],[3:0],[3:0]}),
	.rst_l(),
        .clk(clk));

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan),
        .clk());

assign dp_data_mecc0_int = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan));

assign  = que_wr_channel_mux ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan =  ? ch1_dp_data_mecc0 : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan ?  : dp_data_mecc0;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan : ;
assign dp_data_mecc1_int = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
assign  = que_wr_channel_mux ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan =  ? ch1_dp_data_mecc1 : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan ?  : dp_data_mecc1;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan : ;
assign dp_data_mecc2_int = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
assign  = que_wr_channel_mux ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan =  ? ch1_dp_data_mecc2 : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan ?  : dp_data_mecc2;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan : ;
assign dp_data_mecc3_int = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
assign  = que_wr_channel_mux ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan =  ? ch1_dp_data_mecc3 : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan ?  : dp_data_mecc3;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan : ;
assign dp_data_mecc4_int = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
assign  = que_wr_channel_mux ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan =  ? ch1_dp_data_mecc4 : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan ?  : dp_data_mecc4;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan : ;
assign dp_data_mecc5_int = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
assign  = que_wr_channel_mux ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan =  ? ch1_dp_data_mecc5 : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan ?  : dp_data_mecc5;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan : ;
assign dp_data_mecc6_int = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan;
assign  = que_wr_channel_mux ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan =  ? ch1_dp_data_mecc6 : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan ?  : dp_data_mecc6;
assign dp_data_mecc7_int = que_wr_chan : ;
assign dp_data_mecc7_int = que_wr_chan;
assign  = que_wr_chan =  ? ch1_dp_data_mecc7 : dp_data_mecc7;

assign dp_pioson_l2_data[3:0] = (que_mem_addr_d1[3:1] == 3'h0) ? dp_data_mecc0_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h1) ? dp_data_mecc1_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h2) ? dp_data_mecc2_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h3) ? dp_data_mecc3_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h4) ? dp_data_mecc4_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h5) ? dp_data_mecc5_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h6) ? dp_data_mecc6_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h7) ? dp_data_mecc7_int[3:0] : 4'h0;

dff_ns #(5)	ff_mem_addr(
		.din(que_mem_addr[4:0]),
		.q({que_dp_wr_data_vld, que_mem_addr_d1[3:0]}),
		.clk(clk));

assign dp_pioson_l2_chunk = ( (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) |
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ) ? 2'h0 :
				(que_mem_addr_d1[0] == 1'b0) ? dp_pioson_l2_data[1:0] :
								dp_pioson_l2_data[3:2]; 

// counter to keep track of scrb write back data bypass enable

wire dp_scrb_wr_data_en = que_bypass_scrb_data | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: ?  : dp_data_mecc7;

assign dp_pioson_l2_data[3:0] = (que_mem_addr_d1[3:1] == 3'h0) ? dp_data_mecc0_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h1) ? dp_data_mecc1_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h2) ? dp_data_mecc2_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h3) ? dp_data_mecc3_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h4) ? dp_data_mecc4_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h5) ? dp_data_mecc5_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h6) ? dp_data_mecc6_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h7) ? dp_data_mecc7_int[3:0] : 4'h0;

dff_ns #(5)	ff_mem_addr(
		.din(que_mem_addr[4:0]),
		.q({que_dp_wr_data_vld, que_mem_addr_d1[3:0]}),
		.clk(clk));

assign dp_pioson_l2_chunk = ( (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) |
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ) ? 2'h0 :
				(que_mem_addr_d1[0] == 1'b0) ? dp_pioson_l2_data[1:0] :
								dp_pioson_l2_data[3:2]; 

// counter to keep track of scrb write back data bypass enable

wire dp_scrb_wr_data_en = que_bypass_scrb_data | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: : ;

assign dp_pioson_l2_data[3:0] = (que_mem_addr_d1[3:1] == 3'h0) ? dp_data_mecc0_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h1) ? dp_data_mecc1_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h2) ? dp_data_mecc2_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h3) ? dp_data_mecc3_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h4) ? dp_data_mecc4_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h5) ? dp_data_mecc5_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h6) ? dp_data_mecc6_int[3:0] :
				(que_mem_addr_d1[3:1] == 3'h7) ? dp_data_mecc7_int[3:0] : 4'h0;

dff_ns #(5)	ff_mem_addr(
		.din(que_mem_addr[4:0]),
		.q({que_dp_wr_data_vld, que_mem_addr_d1[3:0]}),
		.clk(clk));

assign dp_pioson_l2_chunk = ( (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) |
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ) ? 2'h0 :
				(que_mem_addr_d1[0] == 1'b0) ? dp_pioson_l2_data[1:0] :
								dp_pioson_l2_data[3:2]; 

// counter to keep track of scrb write back data bypass enable

wire dp_scrb_wr_data_en = que_bypass_scrb_data | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:;

assign [3:0] = ([3:1] == 3hh) ? [3:0] :
				([3:1] == 3hh) ? [3:0] :
				([3:1] == 3hh) ? [3:0] :
				([3:1] == 3hh) ? [3:0] :
				([3:1] == 3hh) ? [3:0] :
				([3:1] == 3hh) ? [3:0] :
				([3:1] == 3hh) ? [3:0] :
				([3:1] == 3hh) ? [3:0] : 4hh;

dff_ns #(5)	(
		.din(que_mem_addr[4:0]),
		.q({que_dp_wr_data_vld, que_mem_addr_d1[3:0]}),
		.clk(clk));

assign dp_pioson_l2_chunk = ( (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) |
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ) ? 2'h0 :
				(que_mem_addr_d1[0] == 1'b0) ? dp_pioson_l2_data[1:0] :
								dp_pioson_l2_data[3:2]; 

// counter to keep track of scrb write back data bypass enable

wire dp_scrb_wr_data_en = que_bypass_scrb_data | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:(
		.din([4:0]),
		.q({, que_mem_addr_d1[3:0]}),
		.clk(clk));

assign dp_pioson_l2_chunk = ( (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) |
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ) ? 2'h0 :
				(que_mem_addr_d1[0] == 1'b0) ? dp_pioson_l2_data[1:0] :
								dp_pioson_l2_data[3:2]; 

// counter to keep track of scrb write back data bypass enable

wire dp_scrb_wr_data_en = que_bypass_scrb_data | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:, [3:0]}),
		.clk());

assign dp_pioson_l2_chunk = ( (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) |
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ) ? 2'h0 :
				(que_mem_addr_d1[0] == 1'b0) ? dp_pioson_l2_data[1:0] :
								dp_pioson_l2_data[3:2]; 

// counter to keep track of scrb write back data bypass enable

wire dp_scrb_wr_data_en = que_bypass_scrb_data | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:));

assign  = ( (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) |
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ) ? 2'h0 :
				(que_mem_addr_d1[0] == 1'b0) ? dp_pioson_l2_data[1:0] :
								dp_pioson_l2_data[3:2]; 

// counter to keep track of scrb write back data bypass enable

wire dp_scrb_wr_data_en = que_bypass_scrb_data | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: = ( ( & dp_scrb_wr_data_en_cnt == 1'b0) |
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ) ? 2'h0 :
				(que_mem_addr_d1[0] == 1'b0) ? dp_pioson_l2_data[1:0] :
								dp_pioson_l2_data[3:2]; 

// counter to keep track of scrb write back data bypass enable

wire dp_scrb_wr_data_en = que_bypass_scrb_data | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: &  == 1'b0) |
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ) ? 2'h0 :
				(que_mem_addr_d1[0] == 1'b0) ? dp_pioson_l2_data[1:0] :
								dp_pioson_l2_data[3:2]; 

// counter to keep track of scrb write back data bypass enable

wire dp_scrb_wr_data_en = que_bypass_scrb_data | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: == 1bb) |
				(~ & dp_scrb_wr_data_en_cnt == 1'b1) ) ? 2'h0 :
				(que_mem_addr_d1[0] == 1'b0) ? dp_pioson_l2_data[1:0] :
								dp_pioson_l2_data[3:2]; 

// counter to keep track of scrb write back data bypass enable

wire dp_scrb_wr_data_en = que_bypass_scrb_data | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: &  == 1'b1) ) ? 2'h0 :
				(que_mem_addr_d1[0] == 1'b0) ? dp_pioson_l2_data[1:0] :
								dp_pioson_l2_data[3:2]; 

// counter to keep track of scrb write back data bypass enable

wire dp_scrb_wr_data_en = que_bypass_scrb_data | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: == 1bb) ) ? 2hh :
				([0] == 1bb) ? [1:0] :
								[3:2]; 


wire  = que_bypass_scrb_data | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: =  | dp_scrb_wr_data_en_cnt;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: | ;
assign dp_scrb_wr_data_en_cnt_in = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:;
assign  = dp_scrb_wr_data_en_cnt + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: =  + 1'b1;

dffrle_ns #(1)  ff_wr_data_en(
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: + 1bb;

dffrle_ns #(1)  (
                .din(dp_scrb_wr_data_en_cnt_in),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:(
                .din(),
                .q(dp_scrb_wr_data_en_cnt),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:),
                .q(),
                .rst_l(rst_l),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:),
                .rst_l(),
                .en(dp_scrb_wr_data_en),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:),
                .en(),
                .clk(clk));

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:),
                .clk());

assign dp_mux_data[255:0] = 
		~que_channel_disabled & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:));

assign [255:0] = 
		~ & (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: & ( & dp_scrb_wr_data_en_cnt == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: &  == 1'b0) ? 
				dp_scrb_data0[255:0] :
		~que_channel_disabled & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: == 1bb) ? 
				[255:0] :
		~ & (~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: & (~ & dp_scrb_wr_data_en_cnt == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: &  == 1'b1) ? 
				dp_scrb_data1[255:0] :
		~que_channel_disabled & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: == 1bb) ? 
				[255:0] :
		~ & ~que_dp_wr_data_vld ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: & ~ ? que_mem_data[255:0] : 
			que_wr_channel_mux ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: ? [255:0] : 
			 ? ch1_que_mem_data : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: ?  : 256'h0;

dram_ecc_gen	ecc_gen_h(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: : 256hh;

dram_ecc_gen	(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_hi),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:(
   			   			.ecc(),
   			// Intputs
			.data({dp_mux_data[191:128], dp_mux_data[255:192]}));

dram_ecc_gen	ecc_gen_l(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:),
   						.data({[191:128], [255:192]}));

dram_ecc_gen	(
   			// Outputs
   			.ecc(dp_mux_ecc_pre_xor_lo),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:(
   			   			.ecc(),
   			// Intputs
			.data({dp_mux_data[63:0], dp_mux_data[127:64]}));

// Need to XOR ecc generated with address parity
// Save the parity till the memory addr is not changed or a new store happens
// que_st_cmd_addr_parity is one cycle ahead of data for stores

dffe_ns #(1)  	ff_st_addr_parity(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:),
   						.data({[63:0], [127:64]}));


dffe_ns #(1)  	(
                .din(que_st_cmd_addr_parity),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:(
                .din(),
                .q(dp_mem_st_cmd_addr_parity),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:),
                .q(),
		.en(~que_mem_addr[0]),
                .clk(clk));

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:),
		.en(~[0]),
                .clk());

// Save the parity till two cycles for scrub as the data is written back to back to memory

dff_ns #(1)  	ff_st_addr_parity_d1(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:));


dff_ns #(1)  	(
                .din(que_st_cmd_addr_parity),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:(
                .din(),
                .q(que_scrb_cmd_addr_parity_d1),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:),
                .q(),
                .clk(clk));

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:),
                .clk());

dff_ns #(1)  	ff_st_addr_parity_d2(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:));

dff_ns #(1)  	(
                .din(que_scrb_cmd_addr_parity_d1),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:(
                .din(),
                .q(que_scrb_cmd_addr_parity_d2),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:),
                .q(),
                .clk(clk));

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:),
                .clk());

wire dp_st_cmd_addr_parity = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:));

wire  = que_bypass_scrb_data ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: =  ? que_scrb_cmd_addr_parity_d1 : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: ?  : 
				(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: : 
				(~ & dp_scrb_wr_data_en_cnt == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: &  == 1'b1) ? que_scrb_cmd_addr_parity_d2 :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: == 1bb) ?  :
				dp_mem_st_cmd_addr_parity;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: :
				;
assign dp_mux_ecc_hi = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:;
assign  = dp_mux_ecc_pre_xor_hi ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: =  ^ {16{dp_st_cmd_addr_parity}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: ^ {16{}};
assign dp_mux_ecc_lo = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:}};
assign  = dp_mux_ecc_pre_xor_lo ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: =  ^ {16{dp_st_cmd_addr_parity}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: ^ {16{}};

assign ecch[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:}};

assign [15:0] = ( & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: &  == 1'b0 & dp_scrb_ecc0[32]) ? 
				dp_scrb_ecc0[15:0] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: == 1bb & [32]) ? 
				[15:0] :
		(~ & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: &  == 1'b1 & dp_scrb_ecc1[32]) ? 
				dp_scrb_ecc1[15:0] : dp_mux_ecc_hi[15:0]; 

assign eccl[15:0] = (que_bypass_scrb_data & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: == 1bb & [32]) ? 
				[15:0] : [15:0]; 

assign [15:0] = ( & dp_scrb_wr_data_en_cnt == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: &  == 1'b0 & dp_scrb_ecc0[33]) ? 
				dp_scrb_ecc0[31:16] :
		(~dp_scrb_data1_en & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: == 1bb & [33]) ? 
				[31:16] :
		(~ & dp_scrb_wr_data_en_cnt == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: &  == 1'b1 & dp_scrb_ecc1[33]) ? 
				dp_scrb_ecc1[31:16] : dp_mux_ecc_lo[15:0]; 

// Generate 16 bit vector that injects error
wire [15:0]	dp_err_inj_vec;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: == 1bb & [33]) ? 
				[31:16] : [15:0]; 

wire [15:0]	;

assign dp_err_inj_vec = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:;

assign  = {16{err_inj_reg}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191: = {16{}} & err_mask_reg[15:0];

assign dp_pad_data[287:0] = {dp_pioson_l2_chunk[1] ^ ecch[15] ^ (dp_err_inj_vec[15] & ~sshot_err_reg), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:}} & [15:0];

assign [287:0] = {[1] ^ [15] ^ ([15] & ~), 
				ecch[14:9] ^ (dp_err_inj_vec[14:9] & {6{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:), 
				[14:9] ^ ([14:9] & {6{~}}), 
			dp_pioson_l2_chunk[1] ^ ecch[8] ^ (dp_err_inj_vec[8] & ~sshot_err_reg), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:}}), 
			[1] ^ [8] ^ ([8] & ~), 
				ecch[7:5] ^ (dp_err_inj_vec[7:5] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:), 
				[7:5] ^ ([7:5] & {3{~}}), 
			dp_pioson_l2_chunk[1] ^ ecch[4] ^ (dp_err_inj_vec[4] & ~sshot_err_reg), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:}}), 
			[1] ^ [4] ^ ([4] & ~), 
				ecch[3:1] ^ (dp_err_inj_vec[3:1] & {3{~sshot_err_reg}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:), 
				[3:1] ^ ([3:1] & {3{~}}), 
			dp_pioson_l2_chunk[1] ^ ecch[0] ^ (dp_err_inj_vec[0] & ~sshot_err_reg), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:}}), 
			[1] ^ [0] ^ ([0] & ~), 
			dp_mux_data[191:128], dp_mux_data[255:192],
			dp_pioson_l2_chunk[0] ^ eccl[15] ^ dp_err_inj_vec[15], 
				eccl[14:9] ^ dp_err_inj_vec[14:9], 
			dp_pioson_l2_chunk[0] ^ eccl[8] ^ dp_err_inj_vec[8], 
				eccl[7:5] ^ dp_err_inj_vec[7:5], 
			dp_pioson_l2_chunk[0] ^ eccl[4] ^ dp_err_inj_vec[4], 
				eccl[3:1] ^ dp_err_inj_vec[3:1], 
			dp_pioson_l2_chunk[0] ^ eccl[0] ^ dp_err_inj_vec[0], 
				dp_mux_data[63:0], dp_mux_data[127:64]}; 

dff_ns #(288)   ff_wr_pad_data(
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:), 
			[191:128], [255:192],
			[0] ^ [15] ^ [15], 
				[14:9] ^ [14:9], 
			[0] ^ [8] ^ [8], 
				[7:5] ^ [7:5], 
			[0] ^ [4] ^ [4], 
				[3:1] ^ [3:1], 
			[0] ^ [0] ^ [0], 
				[63:0], [127:64]}; 

dff_ns #(288)   (
                .din(dp_pad_data[287:0]),
                .q(dp_wr_data_muxed_nibbles[287:0]),
                .clk(clk));

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:(
                .din([287:0]),
                .q([287:0]),
                .clk());

// ecc[287:272]
assign dram_io_data_out[287:284] = dram_fail_over_mask[31] ? dp_wr_data_muxed_nibbles[271:268] : dp_wr_data_muxed_nibbles[287:284];
assign dram_io_data_out[283:280] = dram_fail_over_mask[32] ? dp_wr_data_muxed_nibbles[287:284] : dp_wr_data_muxed_nibbles[283:280];
assign dram_io_data_out[279:276] = dram_fail_over_mask[33] ? dp_wr_data_muxed_nibbles[283:280] : dp_wr_data_muxed_nibbles[279:276];
assign dram_io_data_out[275:272] = dram_fail_over_mask[34] ? dp_wr_data_muxed_nibbles[279:276] : dp_wr_data_muxed_nibbles[275:272];

// data[271:144]
assign dram_io_data_out[271:268] = dram_fail_over_mask[30] ? dp_wr_data_muxed_nibbles[267:264] : dp_wr_data_muxed_nibbles[271:268];
assign dram_io_data_out[267:264] = dram_fail_over_mask[29] ? dp_wr_data_muxed_nibbles[263:260] : dp_wr_data_muxed_nibbles[267:264]; 
assign dram_io_data_out[263:260] = dram_fail_over_mask[28] ? dp_wr_data_muxed_nibbles[259:256] : dp_wr_data_muxed_nibbles[263:260]; 
assign dram_io_data_out[259:256] = dram_fail_over_mask[27] ? dp_wr_data_muxed_nibbles[255:252] : dp_wr_data_muxed_nibbles[259:256]; 
assign dram_io_data_out[255:252] = dram_fail_over_mask[26] ? dp_wr_data_muxed_nibbles[251:248] : dp_wr_data_muxed_nibbles[255:252]; 
assign dram_io_data_out[251:248] = dram_fail_over_mask[25] ? dp_wr_data_muxed_nibbles[247:244] : dp_wr_data_muxed_nibbles[251:248]; 
assign dram_io_data_out[247:244] = dram_fail_over_mask[24] ? dp_wr_data_muxed_nibbles[243:240] : dp_wr_data_muxed_nibbles[247:244]; 
assign dram_io_data_out[243:240] = dram_fail_over_mask[23] ? dp_wr_data_muxed_nibbles[239:236] : dp_wr_data_muxed_nibbles[243:240]; 
assign dram_io_data_out[239:236] = dram_fail_over_mask[22] ? dp_wr_data_muxed_nibbles[235:232] : dp_wr_data_muxed_nibbles[239:236]; 
assign dram_io_data_out[235:232] = dram_fail_over_mask[21] ? dp_wr_data_muxed_nibbles[231:228] : dp_wr_data_muxed_nibbles[235:232]; 
assign dram_io_data_out[231:228] = dram_fail_over_mask[20] ? dp_wr_data_muxed_nibbles[227:224] : dp_wr_data_muxed_nibbles[231:228]; 
assign dram_io_data_out[227:224] = dram_fail_over_mask[19] ? dp_wr_data_muxed_nibbles[223:220] : dp_wr_data_muxed_nibbles[227:224]; 
assign dram_io_data_out[223:220] = dram_fail_over_mask[18] ? dp_wr_data_muxed_nibbles[219:216] : dp_wr_data_muxed_nibbles[223:220]; 
assign dram_io_data_out[219:216] = dram_fail_over_mask[17] ? dp_wr_data_muxed_nibbles[215:212] : dp_wr_data_muxed_nibbles[219:216]; 
assign dram_io_data_out[215:212] = dram_fail_over_mask[16] ? dp_wr_data_muxed_nibbles[211:208] : dp_wr_data_muxed_nibbles[215:212]; 
assign dram_io_data_out[211:208] = dram_fail_over_mask[15] ? dp_wr_data_muxed_nibbles[207:204] : dp_wr_data_muxed_nibbles[211:208]; 
assign dram_io_data_out[207:204] = dram_fail_over_mask[14] ? dp_wr_data_muxed_nibbles[203:200] : dp_wr_data_muxed_nibbles[207:204]; 
assign dram_io_data_out[203:200] = dram_fail_over_mask[13] ? dp_wr_data_muxed_nibbles[199:196] : dp_wr_data_muxed_nibbles[203:200]; 
assign dram_io_data_out[199:196] = dram_fail_over_mask[12] ? dp_wr_data_muxed_nibbles[195:192] : dp_wr_data_muxed_nibbles[199:196]; 
assign dram_io_data_out[195:192] = dram_fail_over_mask[11] ? dp_wr_data_muxed_nibbles[191:188] : dp_wr_data_muxed_nibbles[195:192]; 
assign dram_io_data_out[191:));

assign [287:284] = [31] ? [271:268] : [287:284];
assign [283:280] = [32] ? [287:284] : [283:280];
assign [279:276] = [33] ? [283:280] : [279:276];
assign [275:272] = [34] ? [279:276] : [275:272];

assign [271:268] = [30] ? [267:264] : [271:268];
assign [267:264] = [29] ? [263:260] : [267:264]; 
assign [263:260] = [28] ? [259:256] : [263:260]; 
assign [259:256] = [27] ? [255:252] : [259:256]; 
assign [255:252] = [26] ? [251:248] : [255:252]; 
assign [251:248] = [25] ? [247:244] : [251:248]; 
assign [247:244] = [24] ? [243:240] : [247:244]; 
assign [243:240] = [23] ? [239:236] : [243:240]; 
assign [239:236] = [22] ? [235:232] : [239:236]; 
assign [235:232] = [21] ? [231:228] : [235:232]; 
assign [231:228] = [20] ? [227:224] : [231:228]; 
assign [227:224] = [19] ? [223:220] : [227:224]; 
assign [223:220] = [18] ? [219:216] : [223:220]; 
assign [219:216] = [17] ? [215:212] : [219:216]; 
assign [215:212] = [16] ? [211:208] : [215:212]; 
assign [211:208] = [15] ? [207:204] : [211:208]; 
assign [207:204] = [14] ? [203:200] : [207:204]; 
assign [203:200] = [13] ? [199:196] : [203:200]; 
assign [199:196] = [12] ? [195:192] : [199:196]; 
assign [195:192] = [11] ? [191:188] : [195:192]; 
assign [191:188] = [10] ? [187:184] : [191:188]; 
assign [187:184] = [9] ? [183:180] : [187:184]; 
assign [183:180] = [8] ? [179:176] : [183:180]; 
assign [179:176] = [7] ? [175:172] : [179:176]; 
assign [175:172] = [6] ? [171:168] : [175:172]; 
assign [171:168] = [5] ? [167:164] : [171:168]; 
assign [167:164] = [4] ? [163:160] : [167:164]; 
assign [163:160] = [3] ? [159:156] : [163:160]; 
assign [159:156] = [2] ? [155:152] : [159:156]; 
assign [155:152] = [1] ? [151:148] : [155:152]; 
assign [151:148] = [0] ? [147:144] : [151:148]; 
assign [147:144] = [147:144]; 

assign [143:140] = [31] ? [127:124] : [143:140];
assign [139:136] = [32] ? [143:140] : [139:136];
assign [135:132] = [33] ? [139:136] : [135:132];
assign [131:128] = [34] ? [135:132] : [131:128];

assign [127:124] = [30] ? [123:120] : [127:124];
assign [123:120] = [29] ? [119:116] : [123:120]; 
assign [119:116] = [28] ? [115:112] : [119:116]; 
assign [115:112] = [27] ? [111:108] : [115:112]; 
assign [111:108] = [26] ? [107:104] : [111:108]; 
assign [107:104] = [25] ? [103:100] : [107:104]; 
assign [103:100] = [24] ? [99:96] : [103:100]; 
assign [99:96] = [23] ? [95:92] : [99:96]; 
assign [95:92] = [22] ? [91:88] : [95:92]; 
assign [91:88] = [21] ? [87:84] : [91:88]; 
assign [87:84] = [20] ? [83:80] : [87:84]; 
assign [83:80] = [19] ? [79:76] : [83:80]; 
assign [79:76] = [18] ? [75:72] : [79:76]; 
assign [75:72] = [17] ? [71:68] : [75:72]; 
assign [71:68] = [16] ? [67:64] : [71:68]; 
assign [67:64] = [15] ? [63:60] : [67:64]; 
assign [63:60] = [14] ? [59:56] : [63:60]; 
assign [59:56] = [13] ? [55:52] : [59:56]; 
assign [55:52] = [12] ? [51:48] : [55:52]; 
assign [51:48] = [11] ? [47:44] : [51:48]; 
assign [47:44] = [10] ? [43:40] : [47:44]; 
assign [43:40] = [9] ? [39:36] : [43:40]; 
assign [39:36] = [8] ? [35:32] : [39:36]; 
assign [35:32] = [7] ? [31:28] : [35:32]; 
assign [31:28] = [6] ? [27:24] : [31:28]; 
assign [27:24] = [5] ? [23:20] : [27:24]; 
assign [23:20] = [4] ? [19:16] : [23:20]; 
assign [19:16] = [3] ? [15:12] : [19:16]; 
assign [15:12] = [2] ? [11:8] : [15:12]; 
assign [11:8] = [1] ? [7:4] : [11:8]; 
assign [7:4] = [0] ? [3:0] : [7:4]; 
assign [3:0] = [3:0]; 

wire 		;
wire 		dp_data_vld_cnt;
wire		dp_data_valid_in;

assign dp_data_vld_cnt_in = dp_data_vld_cnt + 1'b1;
assign dp_data_valid_in =  io_dram_data_valid | (|dp_data_vld_cnt);

dffrle_ns #(1)   ff_data_valid_cnt(
                .din(dp_data_vld_cnt_in),
                .q(dp_data_vld_cnt),
		.rst_l(rst_l),
		.en(dp_data_valid_in),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2;
wire 		;
wire		dp_data_valid_in;

assign dp_data_vld_cnt_in = dp_data_vld_cnt + 1'b1;
assign dp_data_valid_in =  io_dram_data_valid | (|dp_data_vld_cnt);

dffrle_ns #(1)   ff_data_valid_cnt(
                .din(dp_data_vld_cnt_in),
                .q(dp_data_vld_cnt),
		.rst_l(rst_l),
		.en(dp_data_valid_in),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2;
wire		;

assign dp_data_vld_cnt_in = dp_data_vld_cnt + 1'b1;
assign dp_data_valid_in =  io_dram_data_valid | (|dp_data_vld_cnt);

dffrle_ns #(1)   ff_data_valid_cnt(
                .din(dp_data_vld_cnt_in),
                .q(dp_data_vld_cnt),
		.rst_l(rst_l),
		.en(dp_data_valid_in),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2;

assign  = dp_data_vld_cnt + 1'b1;
assign dp_data_valid_in =  io_dram_data_valid | (|dp_data_vld_cnt);

dffrle_ns #(1)   ff_data_valid_cnt(
                .din(dp_data_vld_cnt_in),
                .q(dp_data_vld_cnt),
		.rst_l(rst_l),
		.en(dp_data_valid_in),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2 =  + 1'b1;
assign dp_data_valid_in =  io_dram_data_valid | (|dp_data_vld_cnt);

dffrle_ns #(1)   ff_data_valid_cnt(
                .din(dp_data_vld_cnt_in),
                .q(dp_data_vld_cnt),
		.rst_l(rst_l),
		.en(dp_data_valid_in),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2 + 1bb;
assign  =  io_dram_data_valid | (|dp_data_vld_cnt);

dffrle_ns #(1)   ff_data_valid_cnt(
                .din(dp_data_vld_cnt_in),
                .q(dp_data_vld_cnt),
		.rst_l(rst_l),
		.en(dp_data_valid_in),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2 =   | (|dp_data_vld_cnt);

dffrle_ns #(1)   ff_data_valid_cnt(
                .din(dp_data_vld_cnt_in),
                .q(dp_data_vld_cnt),
		.rst_l(rst_l),
		.en(dp_data_valid_in),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2 | (|);

dffrle_ns #(1)   ff_data_valid_cnt(
                .din(dp_data_vld_cnt_in),
                .q(dp_data_vld_cnt),
		.rst_l(rst_l),
		.en(dp_data_valid_in),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2);

dffrle_ns #(1)   (
                .din(dp_data_vld_cnt_in),
                .q(dp_data_vld_cnt),
		.rst_l(rst_l),
		.en(dp_data_valid_in),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2(
                .din(),
                .q(dp_data_vld_cnt),
		.rst_l(rst_l),
		.en(dp_data_valid_in),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2),
                .q(),
		.rst_l(rst_l),
		.en(dp_data_valid_in),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2),
		.rst_l(),
		.en(dp_data_valid_in),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2),
		.en(),
                .clk(clk));

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2),
                .clk());

dffrl_ns #(1)    ff_l2_data_valid(
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2));

dffrl_ns #(1)    (
                .din(dp_data_valid_in),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2(
                .din(),
                .q(dp_data_valid),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2),
                .q(),
		.rst_l(rst_l),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2),
		.rst_l(),
                .clk(clk));

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2),
                .clk());

// Forwarding data from pad to L2 cpu clk domain
// Before that we have implement the reverse of fail over mode mux we introduced.
wire [255:0]	dp_rd_data_muxed_nibbles;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2));

wire [255:0]	;
wire [31:0]	dp_rd_ecc_muxed_nibbles;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2;
wire [31:0]	;

// ecc[31:16]
assign dp_rd_ecc_muxed_nibbles[31:28] = dram_fail_over_mask[32] ? io_dram_ecc_in[27:24] : io_dram_ecc_in[31:28]; 
assign dp_rd_ecc_muxed_nibbles[27:24] = dram_fail_over_mask[33] ? io_dram_ecc_in[23:20] : io_dram_ecc_in[27:24]; 
assign dp_rd_ecc_muxed_nibbles[23:20] = dram_fail_over_mask[34] ? io_dram_ecc_in[19:16] : io_dram_ecc_in[23:20]; 
assign dp_rd_ecc_muxed_nibbles[19:16] = io_dram_ecc_in[19:16]; 

// data[255:128]
assign dp_rd_data_muxed_nibbles[255:252] = dram_fail_over_mask[31] ? io_dram_ecc_in[31:28] : io_dram_data_in[255:252];
assign dp_rd_data_muxed_nibbles[251:248] = dram_fail_over_mask[30] ? io_dram_data_in[255:252] : io_dram_data_in[251:248];
assign dp_rd_data_muxed_nibbles[247:244] = dram_fail_over_mask[29] ? io_dram_data_in[251:248] : io_dram_data_in[247:244]; 
assign dp_rd_data_muxed_nibbles[243:240] = dram_fail_over_mask[28] ? io_dram_data_in[247:244] : io_dram_data_in[243:240]; 
assign dp_rd_data_muxed_nibbles[239:236] = dram_fail_over_mask[27] ? io_dram_data_in[243:240] : io_dram_data_in[239:236]; 
assign dp_rd_data_muxed_nibbles[235:232] = dram_fail_over_mask[26] ? io_dram_data_in[239:236] : io_dram_data_in[235:232]; 
assign dp_rd_data_muxed_nibbles[231:228] = dram_fail_over_mask[25] ? io_dram_data_in[235:232] : io_dram_data_in[231:2;

assign [31:28] = [32] ? [27:24] : [31:28]; 
assign [27:24] = [33] ? [23:20] : [27:24]; 
assign [23:20] = [34] ? [19:16] : [23:20]; 
assign [19:16] = [19:16]; 

assign [255:252] = [31] ? [31:28] : [255:252];
assign [251:248] = [30] ? [255:252] : [251:248];
assign [247:244] = [29] ? [251:248] : [247:244]; 
assign [243:240] = [28] ? [247:244] : [243:240]; 
assign [239:236] = [27] ? [243:240] : [239:236]; 
assign [235:232] = [26] ? [239:236] : [235:232]; 
assign [231:228] = [25] ? [235:232] : [231:228]; 
assign [227:224] = [24] ? [231:228] : [227:224]; 
assign [223:220] = [23] ? [227:224] : [223:220]; 
assign [219:216] = [22] ? [223:220] : [219:216]; 
assign [215:212] = [21] ? [219:216] : [215:212]; 
assign [211:208] = [20] ? [215:212] : [211:208]; 
assign [207:204] = [19] ? [211:208] : [207:204]; 
assign [203:200] = [18] ? [207:204] : [203:200]; 
assign [199:196] = [17] ? [203:200] : [199:196]; 
assign [195:192] = [16] ? [199:196] : [195:192]; 
assign [191:188] = [15] ? [195:192] : [191:188]; 
assign [187:184] = [14] ? [191:188] : [187:184]; 
assign [183:180] = [13] ? [187:184] : [183:180]; 
assign [179:176] = [12] ? [183:180] : [179:176]; 
assign [175:172] = [11] ? [179:176] : [175:172]; 
assign [171:168] = [10] ? [175:172] : [171:168]; 
assign [167:164] = [9] ? [171:168] : [167:164]; 
assign [163:160] = [8] ? [167:164] : [163:160]; 
assign [159:156] = [7] ? [163:160] : [159:156]; 
assign [155:152] = [6] ? [159:156] : [155:152]; 
assign [151:148] = [5] ? [155:152] : [151:148]; 
assign [147:144] = [4] ? [151:148] : [147:144]; 
assign [143:140] = [3] ? [147:144] : [143:140]; 
assign [139:136] = [2] ? [143:140] : [139:136]; 
assign [135:132] = [1] ? [139:136] : [135:132]; 
assign [131:128] = [0] ? [135:132] : [131:128]; 

assign [15:12] = [32] ? [11:8] : [15:12]; 
assign [11:8] = [33] ? [7:4] : [11:8]; 
assign [7:4] = [34] ? [3:0] : [7:4]; 
assign [3:0] = [3:0]; 

assign [127:124] = [31] ? [15:12] : [127:124]; 
assign [123:120] = [30] ? [127:124] : [123:120]; 
assign [119:116] = [29] ? [123:120] : [119:116]; 
assign [115:112] = [28] ? [119:116] : [115:112]; 
assign [111:108] = [27] ? [115:112] : [111:108]; 
assign [107:104] = [26] ? [111:108] : [107:104]; 
assign [103:100] = [25] ? [107:104] : [103:100]; 
assign [99:96] = [24] ? [103:100] : [99:96]; 
assign [95:92] = [23] ? [99:96] : [95:92]; 
assign [91:88] = [22] ? [95:92] : [91:88]; 
assign [87:84] = [21] ? [91:88] : [87:84]; 
assign [83:80] = [20] ? [87:84] : [83:80]; 
assign [79:76] = [19] ? [83:80] : [79:76]; 
assign [75:72] = [18] ? [79:76] : [75:72]; 
assign [71:68] = [17] ? [75:72] : [71:68]; 
assign [67:64] = [16] ? [71:68] : [67:64]; 
assign [63:60] = [15] ? [67:64] : [63:60]; 
assign [59:56] = [14] ? [63:60] : [59:56]; 
assign [55:52] = [13] ? [59:56] : [55:52]; 
assign [51:48] = [12] ? [55:52] : [51:48]; 
assign [47:44] = [11] ? [51:48] : [47:44]; 
assign [43:40] = [10] ? [47:44] : [43:40]; 
assign [39:36] = [9] ? [43:40] : [39:36]; 
assign [35:32] = [8] ? [39:36] : [35:32]; 
assign [31:28] = [7] ? [35:32] : [31:28]; 
assign [27:24] = [6] ? [31:28] : [27:24]; 
assign [23:20] = [5] ? [27:24] : [23:20]; 
assign [19:16] = [4] ? [23:20] : [19:16]; 
assign [15:12] = [3] ? [19:16] : [15:12]; 
assign [11:8] = [2] ? [15:12] : [11:8]; 
assign [7:4] = [1] ? [11:8] : [7:4]; 
assign [3:0] = [0] ? [7:4] : [3:0]; 

dff_ns #(288)      (
                .din({dp_rd_ecc_muxed_nibbles[31:0], dp_rd_data_muxed_nibbles[255:0]}),
                .q({dp_ecc_in[31:0], dp_data_in[255:0]}),
                .clk(clk));

endmodule
(
                .din({[31:0], [255:0]}),
                .q({[31:0], [255:0]}),
                .clk());

endmodule
));

endmodule
